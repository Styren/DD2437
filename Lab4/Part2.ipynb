{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boiler Plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import BernoulliRBM, MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bin_train = np.genfromtxt('data/bindigit_trn.csv',delimiter=',',)\n",
    "target_train = np.genfromtxt('data/targetdigit_trn.csv',delimiter=',',)\n",
    "bin_test = np.genfromtxt('data/bindigit_tst.csv',delimiter=',',)\n",
    "target_test = np.genfromtxt('data/targetdigit_tst.csv',delimiter=',',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def report_DBM(rbms = [150,100,50], iterations = 50, batch_size = 64, learning_rate = 0.01, verbose = True):\n",
    "    #Initialize pipe\n",
    "    networks = []\n",
    "    count = 1\n",
    "    for hidden_dim in rbms:\n",
    "        rbm = BernoulliRBM(n_components = hidden_dim, batch_size = batch_size, learning_rate = learning_rate,\n",
    "                      n_iter = iterations, verbose = verbose, random_state = 0)\n",
    "        networks.append(('rbm{}'.format(count),rbm))\n",
    "        count += 1\n",
    "\n",
    "    networks.append(('mlp',MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam',alpha=0.01)))\n",
    "    model = Pipeline(networks)\n",
    "    \n",
    "    #Train model\n",
    "    model.fit(bin_train, target_train)\n",
    "\n",
    "    #Report results\n",
    "    print(metrics.classification_report(\n",
    "        target_test,\n",
    "        model.predict(bin_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report_DBM(rbms = [], iterations = 100, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_stacked_autoencoders(autoencoders, iterations = 50, batch_size=64 , verbose = True, target_train=target_train):\n",
    "    input_layer = Input(shape=(784,))\n",
    "    layer = input_layer\n",
    "    #encode\n",
    "    for hidden_dim in autoencoders:\n",
    "        layer = Dense(hidden_dim, activation = 'relu')(layer)\n",
    "    autoencoders.pop(-1)\n",
    "    #decode\n",
    "    for hidden_dim in reversed(autoencoders):\n",
    "        layer = Dense(hidden_dim, activation = 'relu')(layer)\n",
    "    layer = Dense(784, activation = 'relu')(layer)\n",
    "    out = Dense(10, activation='sigmoid')(layer)    \n",
    "\n",
    "    target_train = to_categorical(target_train, num_classes=10)\n",
    "    model = Model(input_layer, out)\n",
    "    model.compile(optimizer = 'adadelta', loss = 'mean_squared_error')\n",
    "    model.fit(bin_train,target_train,\n",
    "                   epochs=iterations,\n",
    "                   batch_size=batch_size,\n",
    "                   shuffle=True,\n",
    "                   verbose=verbose)\n",
    "\n",
    "    predictions = np.argmax(model.predict(bin_test),axis=1)\n",
    "    print(metrics.classification_report(target_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report_stacked_autoencoders(autoencoders = [150,100,50], iterations =50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_MLP(layers, iterations = 50, batch_size = 64, verbose = True, target_train = target_train):\n",
    "    model = Sequential()\n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "\n",
    "    target_train = to_categorical(target_train, num_classes=10)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(bin_train,target_train,epochs=iterations,\n",
    "              batch_size=batch_size,verbose=verbose, shuffle=False)\n",
    "    predictions = np.argmax(model.predict(bin_test),axis=1)\n",
    "    print(metrics.classification_report(target_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 1s 151us/step - loss: 0.0968 - acc: 0.2347\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.0539 - acc: 0.6257\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0331 - acc: 0.7956\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0245 - acc: 0.8534\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0195 - acc: 0.8828\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0169 - acc: 0.8988\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0152 - acc: 0.9103\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0140 - acc: 0.9161\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0125 - acc: 0.9253\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.0117 - acc: 0.9313\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.0106 - acc: 0.9384\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.0099 - acc: 0.9415\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.0098 - acc: 0.9407\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.0091 - acc: 0.9464\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.0085 - acc: 0.9489\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.0082 - acc: 0.9519\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.0077 - acc: 0.9556\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.0075 - acc: 0.9561\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 0.0072 - acc: 0.9579\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.0070 - acc: 0.9576\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0065 - acc: 0.9605\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.0062 - acc: 0.9620\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.0064 - acc: 0.9611\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0060 - acc: 0.9646\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.0060 - acc: 0.9641\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.0058 - acc: 0.9652\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.0052 - acc: 0.9696\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.0052 - acc: 0.9681\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.0051 - acc: 0.9684\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.0054 - acc: 0.9670\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.0053 - acc: 0.9675\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0045 - acc: 0.9738\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0044 - acc: 0.9734\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.0044 - acc: 0.9736\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.0045 - acc: 0.9724\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.0042 - acc: 0.9745\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.0044 - acc: 0.9739\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.0045 - acc: 0.9728\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.0043 - acc: 0.9745\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.0039 - acc: 0.9749\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.0043 - acc: 0.9739\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.0041 - acc: 0.9741\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.0041 - acc: 0.9754\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.0038 - acc: 0.9770\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.0035 - acc: 0.9784\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.0035 - acc: 0.9796\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.0035 - acc: 0.9789\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.0038 - acc: 0.9772\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.0037 - acc: 0.9774\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0038 - acc: 0.9772\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.98      0.96       196\n",
      "        1.0       0.97      0.97      0.97       227\n",
      "        2.0       0.93      0.94      0.93       206\n",
      "        3.0       0.97      0.89      0.93       202\n",
      "        4.0       0.96      0.97      0.97       196\n",
      "        5.0       0.91      0.93      0.92       182\n",
      "        6.0       0.94      0.97      0.96       191\n",
      "        7.0       0.95      0.95      0.95       205\n",
      "        8.0       0.96      0.93      0.95       194\n",
      "        9.0       0.96      0.96      0.96       201\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    Dense(150,input_shape=(784,), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(100,input_shape=(784,), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(50,input_shape=(784,), activation='relu'),\n",
    "    Dense(10, activation='sigmoid'),\n",
    "    ]\n",
    "\n",
    "report_MLP(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
